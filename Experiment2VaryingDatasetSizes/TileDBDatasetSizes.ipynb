{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da84c98d-0126-4f55-b220-118d8a93fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain, ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers.txt import TextParser\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.tiledb import TileDB\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67397ecd-a6d6-449d-82a7-e06233952dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "637ff764-dcf1-459a-97cb-442fded2ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing data with different sizes\n",
    "data_source_path = \"/Users/sihamargaw/Desktop/ReseachProject/Dataset/DD\"\n",
    "\n",
    "# LLM and question for retrieval\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# Store timing results for plotting\n",
    "resultsTileDB = {\n",
    "    \"file_name\": [],\n",
    "    \"embedding_time\": [],\n",
    "    \"indexing_time\": [],\n",
    "    \"retrieval_time\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d204b4aa-d58d-444d-bf1f-ec15d10d1f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed copy50.pdf: 199 chunks.\n",
      "Preprocessed copy1000.pdf: 4784 chunks.\n",
      "Preprocessed copy500.pdf: 1915 chunks.\n",
      "Preprocessed copy200.pdf: 762 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Loading\n",
    "documents_dict = {}\n",
    "texts_dict = {}\n",
    "metadata_dict = {}\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(data_source_path)):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(data_source_path, file_name)\n",
    "\n",
    "        # Parse documents and split them into text chunks\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "        documents = loader.load()\n",
    "        documents = splitter.split_documents(documents)\n",
    "        documents = [d for d in documents if len(d.page_content) > 5]\n",
    "        texts = [d.page_content for d in documents]\n",
    "        metadata = [d.metadata for d in documents]\n",
    "\n",
    "        # Store the processed documents and texts for later use\n",
    "        documents_dict[file_name] = documents\n",
    "        texts_dict[file_name] = texts\n",
    "        metadata_dict[file_name] = metadata\n",
    "        print(f\"Preprocessed {file_name}: {len(texts)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dfcecab-2003-4670-a981-c680b6c6908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for copy50.pdf...\n",
      "Embeddings generated for copy50.pdf in 6.087449073791504 seconds\n",
      "Generating embeddings for copy1000.pdf...\n",
      "Embeddings generated for copy1000.pdf in 130.7780442237854 seconds\n",
      "Generating embeddings for copy500.pdf...\n",
      "Embeddings generated for copy500.pdf in 49.90364384651184 seconds\n",
      "Generating embeddings for copy200.pdf...\n",
      "Embeddings generated for copy200.pdf in 21.484942197799683 seconds\n"
     ]
    }
   ],
   "source": [
    "# Embedding Generation\n",
    "embeddings_dict = {}\n",
    "\n",
    "for file_name, texts in texts_dict.items():\n",
    "    print(f\"Generating embeddings for {file_name}...\")\n",
    "    t1 = time.time()\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    text_embeddings = embedding.embed_documents(texts)\n",
    "    t2 = time.time()\n",
    "    embedding_time = t2 - t1\n",
    "    text_embedding_pairs = list(zip(texts, text_embeddings))\n",
    "    embeddings_dict[file_name] = text_embedding_pairs  # Store the embeddings\n",
    "    print(f\"Embeddings generated for {file_name} in {embedding_time} seconds\")\n",
    "\n",
    "    # Store the embedding generation time\n",
    "    resultsTileDB[\"file_name\"].append(file_name)\n",
    "    resultsTileDB[\"embedding_time\"].append(embedding_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef7612b-4f1c-4b52-bde5-5078f4431ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing embeddings for copy50.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sihamargaw/.local/pipx/.cache/5c9468f9a0a782a/lib/python3.12/site-packages/tiledb/cloud/config.py:96: UserWarning: You must first login before you can run commands. Please run tiledb.cloud.login.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing completed for copy50.pdf. Total time: 27.769508123397827s\n",
      "Number of vector embeddings stored in TileDB-Vector-Search for copy50.pdf: 199\n",
      "Indexing embeddings for copy1000.pdf...\n",
      "Indexing completed for copy1000.pdf. Total time: 0.7640290260314941s\n",
      "Number of vector embeddings stored in TileDB-Vector-Search for copy1000.pdf: 4784\n",
      "Indexing embeddings for copy500.pdf...\n",
      "Indexing completed for copy500.pdf. Total time: 0.5565292835235596s\n",
      "Number of vector embeddings stored in TileDB-Vector-Search for copy500.pdf: 1915\n",
      "Indexing embeddings for copy200.pdf...\n",
      "Indexing completed for copy200.pdf. Total time: 0.3616969585418701s\n",
      "Number of vector embeddings stored in TileDB-Vector-Search for copy200.pdf: 762\n"
     ]
    }
   ],
   "source": [
    "# Index document chunks using a TileDB IVF_FLAT index, using langchain's from_embeddings method\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Define the TileDB index URI\n",
    "tiledb_index_uri_base = \"./tiledb_example_index\"\n",
    "\n",
    "for file_name, text_embedding_pairs in embeddings_dict.items():\n",
    "    print(f\"Indexing embeddings for {file_name}...\")\n",
    "    t3 = time.time()\n",
    "\n",
    "    # Prepare the index URI for the specific file\n",
    "    tiledb_index_uri = f\"{tiledb_index_uri_base}_{file_name}\"\n",
    "    \n",
    "    # Remove existing index directory if it exists\n",
    "    if os.path.isdir(tiledb_index_uri):\n",
    "        shutil.rmtree(tiledb_index_uri)\n",
    "    \n",
    "    # Index the embeddings in TileDB\n",
    "    db = TileDB.from_embeddings(\n",
    "        text_embedding_pairs, \n",
    "        embedding,\n",
    "        index_uri=tiledb_index_uri,\n",
    "        index_type=\"IVF_FLAT\",\n",
    "        allow_dangerous_deserialization=True,  # Enabling the bypass for pickle deserialization\n",
    "        metadatas=metadata_dict[file_name]\n",
    "    )\n",
    "    \n",
    "    t4 = time.time()\n",
    "    indexing_time = t4 - t3\n",
    "    print(f\"Embeddings indexed for {file_name} in {indexing_time} seconds\")\n",
    "\n",
    "    # Store the indexing time\n",
    "    resultsTileDB[\"indexing_time\"].append(indexing_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534812af-0785-4612-b00b-71cdec3794d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for copy50.pdf...\n",
      "AI: AI researchers distinguish between human-like intelligence and rational intelligence by focusing on different aspects of intelligence. Human-like intelligence involves understanding how humans think and act, including emotions, creativity, and social interactions. On the other hand, rational intelligence focuses on making decisions based on logical reasoning, probability theory, and machine learning to achieve specific goals efficiently and effectively. While human-like intelligence may involve more complex and nuanced behaviors, rational intelligence aims at achieving optimal outcomes based on defined objectives.\n",
      "\n",
      "Total retrieval time for copy50.pdf: 1.7141239643096924 seconds\n",
      "Retrieving data for copy1000.pdf...\n",
      "AI: AI researchers distinguish between human-like intelligence and rational intelligence by considering two dimensions: human vs. rational and thought vs. behavior. Some researchers define intelligence based on fidelity to human performance, focusing on internal thought processes and reasoning. Others prefer an abstract, formal definition of intelligence called rationality, which involves doing the \"right thing\" and focusing on intelligent behavior as an external characterization. These distinctions help researchers approach AI with different goals in mind, such as modeling humans or achieving optimal results.\n",
      "\n",
      "Total retrieval time for copy1000.pdf: 1.8654577732086182 seconds\n",
      "Retrieving data for copy500.pdf...\n",
      "AI: AI researchers distinguish between human-like intelligence and rational intelligence by considering two dimensions: human vs. rational and thought vs. behavior. Some researchers define intelligence based on fidelity to human performance, focusing on internal thought processes and reasoning. Others prefer an abstract, formal definition of intelligence called rationality, which involves doing the \"right thing\" and focusing on intelligent behavior as an external characterization. These distinctions help researchers approach AI with different goals in mind, such as modeling humans or achieving optimal results.\n",
      "\n",
      "Total retrieval time for copy500.pdf: 2.0761749744415283 seconds\n",
      "Retrieving data for copy200.pdf...\n",
      "AI: AI researchers distinguish between human-like intelligence and rational intelligence by considering two dimensions: human vs. rational and thought vs. behavior. Human-like intelligence focuses on mimicking human thought processes and reasoning, while rational intelligence is more concerned with achieving the optimal results or doing the \"right thing\" in a given situation. The rational intelligence approach is more general and mathematically well-defined, making it easier to develop scientifically compared to imitating human behavior or thought processes.\n",
      "\n",
      "Total retrieval time for copy200.pdf: 2.1220030784606934 seconds\n"
     ]
    }
   ],
   "source": [
    "# Retrieval and Latency Measurement\n",
    "embedding_model = OpenAIEmbeddings()  # Ensure this matches the model used for embedding\n",
    "question = \" How do AI researchers distinguish between human-like intelligence and rational intelligence? \"\n",
    "\n",
    "\n",
    "for i, file_name in enumerate(embeddings_dict):\n",
    "    print(f\"Retrieving data for {file_name}...\")\n",
    "    tiledb_index_uri = f\"{tiledb_index_uri_base}_{file_name}\"\n",
    "\n",
    "    db = TileDB.load(\n",
    "        index_uri=tiledb_index_uri, \n",
    "        embedding=embedding,\n",
    "        allow_dangerous_deserialization=True  # Enable deserialization despite the warning\n",
    "    )\n",
    "\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5},\n",
    "    )\n",
    "    \n",
    "    # Use the retriever with LangChain's ConversationalRetrievalChain\n",
    "    private_chatgpt = ConversationalRetrievalChain.from_llm(llm, retriever=retriever)\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = private_chatgpt.run({'question': question, 'chat_history': ''})\n",
    "    end_time = time.time()\n",
    "\n",
    "    retrieval_time = end_time - start_time\n",
    "    print(f\"AI: {response}\\n\")\n",
    "    print(f\"Total retrieval time for {file_name}: {retrieval_time} seconds\")\n",
    "\n",
    "    # Store the retrieval time\n",
    "    resultsTileDB[\"retrieval_time\"].append(retrieval_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858232a2-35d7-4f16-ae19-46ff1d12fb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a0f916-e82a-4482-8d1c-18eca37f8353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
